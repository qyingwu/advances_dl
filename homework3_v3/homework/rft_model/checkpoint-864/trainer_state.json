{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 24.0,
  "eval_steps": 500,
  "global_step": 864,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1423487544483986,
      "grad_norm": 0.7343539595603943,
      "learning_rate": 1.5151515151515152e-06,
      "loss": 1.8193,
      "step": 5
    },
    {
      "epoch": 0.2846975088967972,
      "grad_norm": 0.8313899636268616,
      "learning_rate": 3.409090909090909e-06,
      "loss": 1.827,
      "step": 10
    },
    {
      "epoch": 0.42704626334519574,
      "grad_norm": 0.6961363554000854,
      "learning_rate": 5.303030303030304e-06,
      "loss": 1.8253,
      "step": 15
    },
    {
      "epoch": 0.5693950177935944,
      "grad_norm": 0.7421309351921082,
      "learning_rate": 7.196969696969698e-06,
      "loss": 1.819,
      "step": 20
    },
    {
      "epoch": 0.7117437722419929,
      "grad_norm": 0.7345272302627563,
      "learning_rate": 9.090909090909091e-06,
      "loss": 1.7681,
      "step": 25
    },
    {
      "epoch": 0.8540925266903915,
      "grad_norm": 0.7426539659500122,
      "learning_rate": 1.0984848484848486e-05,
      "loss": 1.7434,
      "step": 30
    },
    {
      "epoch": 0.99644128113879,
      "grad_norm": 0.7607767581939697,
      "learning_rate": 1.287878787878788e-05,
      "loss": 1.7142,
      "step": 35
    },
    {
      "epoch": 1.113879003558719,
      "grad_norm": 0.7634845972061157,
      "learning_rate": 1.4772727272727274e-05,
      "loss": 1.6831,
      "step": 40
    },
    {
      "epoch": 1.2562277580071175,
      "grad_norm": 0.8860412836074829,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 1.6218,
      "step": 45
    },
    {
      "epoch": 1.398576512455516,
      "grad_norm": 0.8921756148338318,
      "learning_rate": 1.856060606060606e-05,
      "loss": 1.5505,
      "step": 50
    },
    {
      "epoch": 1.5409252669039146,
      "grad_norm": 0.8143285512924194,
      "learning_rate": 2.0454545454545457e-05,
      "loss": 1.4312,
      "step": 55
    },
    {
      "epoch": 1.6832740213523132,
      "grad_norm": 0.7506273984909058,
      "learning_rate": 2.234848484848485e-05,
      "loss": 1.3321,
      "step": 60
    },
    {
      "epoch": 1.8256227758007118,
      "grad_norm": 0.7032800316810608,
      "learning_rate": 2.4242424242424244e-05,
      "loss": 1.253,
      "step": 65
    },
    {
      "epoch": 1.9679715302491103,
      "grad_norm": 0.6025351285934448,
      "learning_rate": 2.6136363636363637e-05,
      "loss": 1.1338,
      "step": 70
    },
    {
      "epoch": 2.0854092526690393,
      "grad_norm": 0.5894941091537476,
      "learning_rate": 2.803030303030303e-05,
      "loss": 1.0896,
      "step": 75
    },
    {
      "epoch": 2.227758007117438,
      "grad_norm": 0.5744621157646179,
      "learning_rate": 2.9924242424242427e-05,
      "loss": 0.927,
      "step": 80
    },
    {
      "epoch": 2.3701067615658364,
      "grad_norm": 0.5225438475608826,
      "learning_rate": 3.181818181818182e-05,
      "loss": 0.8316,
      "step": 85
    },
    {
      "epoch": 2.512455516014235,
      "grad_norm": 0.4816477596759796,
      "learning_rate": 3.371212121212121e-05,
      "loss": 0.7136,
      "step": 90
    },
    {
      "epoch": 2.6548042704626336,
      "grad_norm": 0.4759421944618225,
      "learning_rate": 3.560606060606061e-05,
      "loss": 0.6054,
      "step": 95
    },
    {
      "epoch": 2.797153024911032,
      "grad_norm": 0.3924722373485565,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.5107,
      "step": 100
    },
    {
      "epoch": 2.9395017793594307,
      "grad_norm": 0.3738555908203125,
      "learning_rate": 3.939393939393939e-05,
      "loss": 0.4634,
      "step": 105
    },
    {
      "epoch": 3.0569395017793592,
      "grad_norm": 0.31207382678985596,
      "learning_rate": 4.128787878787879e-05,
      "loss": 0.3885,
      "step": 110
    },
    {
      "epoch": 3.199288256227758,
      "grad_norm": 0.3007187843322754,
      "learning_rate": 4.318181818181819e-05,
      "loss": 0.3787,
      "step": 115
    },
    {
      "epoch": 3.3416370106761564,
      "grad_norm": 0.29052919149398804,
      "learning_rate": 4.5075757575757577e-05,
      "loss": 0.3387,
      "step": 120
    },
    {
      "epoch": 3.4839857651245554,
      "grad_norm": 0.3222266733646393,
      "learning_rate": 4.696969696969697e-05,
      "loss": 0.3601,
      "step": 125
    },
    {
      "epoch": 3.6263345195729535,
      "grad_norm": 0.22925777733325958,
      "learning_rate": 4.886363636363637e-05,
      "loss": 0.3148,
      "step": 130
    },
    {
      "epoch": 3.7686832740213525,
      "grad_norm": 0.3382301926612854,
      "learning_rate": 4.999910609877162e-05,
      "loss": 0.3227,
      "step": 135
    },
    {
      "epoch": 3.9110320284697506,
      "grad_norm": 0.27481237053871155,
      "learning_rate": 4.998905044407372e-05,
      "loss": 0.2931,
      "step": 140
    },
    {
      "epoch": 4.02846975088968,
      "grad_norm": 0.30073896050453186,
      "learning_rate": 4.99678262673653e-05,
      "loss": 0.2892,
      "step": 145
    },
    {
      "epoch": 4.170818505338079,
      "grad_norm": 0.2730819284915924,
      "learning_rate": 4.9935443054508394e-05,
      "loss": 0.2597,
      "step": 150
    },
    {
      "epoch": 4.313167259786477,
      "grad_norm": 0.27764347195625305,
      "learning_rate": 4.9891915278747034e-05,
      "loss": 0.28,
      "step": 155
    },
    {
      "epoch": 4.455516014234876,
      "grad_norm": 0.2481222152709961,
      "learning_rate": 4.983726239423867e-05,
      "loss": 0.2721,
      "step": 160
    },
    {
      "epoch": 4.597864768683274,
      "grad_norm": 0.27195608615875244,
      "learning_rate": 4.9771508827359365e-05,
      "loss": 0.2534,
      "step": 165
    },
    {
      "epoch": 4.740213523131673,
      "grad_norm": 0.28656816482543945,
      "learning_rate": 4.969468396578676e-05,
      "loss": 0.2739,
      "step": 170
    },
    {
      "epoch": 4.882562277580071,
      "grad_norm": 0.2545219659805298,
      "learning_rate": 4.9606822145365634e-05,
      "loss": 0.2553,
      "step": 175
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.6739944815635681,
      "learning_rate": 4.950796263476198e-05,
      "loss": 0.2499,
      "step": 180
    },
    {
      "epoch": 5.142348754448399,
      "grad_norm": 0.23194462060928345,
      "learning_rate": 4.939814961791239e-05,
      "loss": 0.223,
      "step": 185
    },
    {
      "epoch": 5.284697508896797,
      "grad_norm": 0.21364574134349823,
      "learning_rate": 4.927743217427661e-05,
      "loss": 0.2136,
      "step": 190
    },
    {
      "epoch": 5.427046263345196,
      "grad_norm": 0.30795639753341675,
      "learning_rate": 4.914586425690219e-05,
      "loss": 0.2941,
      "step": 195
    },
    {
      "epoch": 5.569395017793594,
      "grad_norm": 0.2719259262084961,
      "learning_rate": 4.900350466831081e-05,
      "loss": 0.255,
      "step": 200
    },
    {
      "epoch": 5.711743772241993,
      "grad_norm": 0.25446903705596924,
      "learning_rate": 4.885041703421735e-05,
      "loss": 0.2101,
      "step": 205
    },
    {
      "epoch": 5.854092526690391,
      "grad_norm": 0.22279226779937744,
      "learning_rate": 4.868666977509321e-05,
      "loss": 0.2299,
      "step": 210
    },
    {
      "epoch": 5.99644128113879,
      "grad_norm": 0.2666567265987396,
      "learning_rate": 4.8512336075586664e-05,
      "loss": 0.2669,
      "step": 215
    },
    {
      "epoch": 6.1138790035587185,
      "grad_norm": 0.27143123745918274,
      "learning_rate": 4.8327493851813996e-05,
      "loss": 0.2269,
      "step": 220
    },
    {
      "epoch": 6.2562277580071175,
      "grad_norm": 0.22361302375793457,
      "learning_rate": 4.8132225716535915e-05,
      "loss": 0.2137,
      "step": 225
    },
    {
      "epoch": 6.398576512455516,
      "grad_norm": 0.28471747040748596,
      "learning_rate": 4.792661894223489e-05,
      "loss": 0.2354,
      "step": 230
    },
    {
      "epoch": 6.540925266903915,
      "grad_norm": 0.2322331964969635,
      "learning_rate": 4.771076542210987e-05,
      "loss": 0.2315,
      "step": 235
    },
    {
      "epoch": 6.683274021352313,
      "grad_norm": 0.2532232403755188,
      "learning_rate": 4.748476162900589e-05,
      "loss": 0.2045,
      "step": 240
    },
    {
      "epoch": 6.825622775800712,
      "grad_norm": 0.23501870036125183,
      "learning_rate": 4.7248708572296756e-05,
      "loss": 0.224,
      "step": 245
    },
    {
      "epoch": 6.967971530249111,
      "grad_norm": 0.2643575072288513,
      "learning_rate": 4.700271175274031e-05,
      "loss": 0.2303,
      "step": 250
    },
    {
      "epoch": 7.085409252669039,
      "grad_norm": 0.23065505921840668,
      "learning_rate": 4.6746881115326266e-05,
      "loss": 0.2277,
      "step": 255
    },
    {
      "epoch": 7.227758007117438,
      "grad_norm": 0.2443932294845581,
      "learning_rate": 4.648133100013773e-05,
      "loss": 0.2124,
      "step": 260
    },
    {
      "epoch": 7.370106761565836,
      "grad_norm": 0.2737179398536682,
      "learning_rate": 4.620618009124848e-05,
      "loss": 0.2156,
      "step": 265
    },
    {
      "epoch": 7.512455516014235,
      "grad_norm": 0.2311892956495285,
      "learning_rate": 4.5921551363678675e-05,
      "loss": 0.2175,
      "step": 270
    },
    {
      "epoch": 7.654804270462633,
      "grad_norm": 0.24015600979328156,
      "learning_rate": 4.5627572028432816e-05,
      "loss": 0.2078,
      "step": 275
    },
    {
      "epoch": 7.797153024911032,
      "grad_norm": 0.2530992925167084,
      "learning_rate": 4.532437347564452e-05,
      "loss": 0.2157,
      "step": 280
    },
    {
      "epoch": 7.93950177935943,
      "grad_norm": 0.26565486192703247,
      "learning_rate": 4.5012091215853395e-05,
      "loss": 0.2111,
      "step": 285
    },
    {
      "epoch": 8.05693950177936,
      "grad_norm": 0.22047583758831024,
      "learning_rate": 4.4690864819440474e-05,
      "loss": 0.2453,
      "step": 290
    },
    {
      "epoch": 8.199288256227758,
      "grad_norm": 0.2621311545372009,
      "learning_rate": 4.436083785424906e-05,
      "loss": 0.2032,
      "step": 295
    },
    {
      "epoch": 8.341637010676157,
      "grad_norm": 0.27746787667274475,
      "learning_rate": 4.402215782141904e-05,
      "loss": 0.191,
      "step": 300
    },
    {
      "epoch": 8.483985765124554,
      "grad_norm": 0.31559109687805176,
      "learning_rate": 4.367497608946318e-05,
      "loss": 0.2101,
      "step": 305
    },
    {
      "epoch": 8.626334519572953,
      "grad_norm": 0.26078587770462036,
      "learning_rate": 4.331944782661499e-05,
      "loss": 0.2091,
      "step": 310
    },
    {
      "epoch": 8.768683274021353,
      "grad_norm": 0.2841464579105377,
      "learning_rate": 4.295573193147842e-05,
      "loss": 0.1842,
      "step": 315
    },
    {
      "epoch": 8.911032028469752,
      "grad_norm": 0.23860321938991547,
      "learning_rate": 4.2583990962010165e-05,
      "loss": 0.1842,
      "step": 320
    },
    {
      "epoch": 9.02846975088968,
      "grad_norm": 0.23192554712295532,
      "learning_rate": 4.220439106286664e-05,
      "loss": 0.2114,
      "step": 325
    },
    {
      "epoch": 9.170818505338078,
      "grad_norm": 0.2599382698535919,
      "learning_rate": 4.181710189114777e-05,
      "loss": 0.1738,
      "step": 330
    },
    {
      "epoch": 9.313167259786477,
      "grad_norm": 0.22919674217700958,
      "learning_rate": 4.14222965405711e-05,
      "loss": 0.2012,
      "step": 335
    },
    {
      "epoch": 9.455516014234876,
      "grad_norm": 0.25597313046455383,
      "learning_rate": 4.10201514641098e-05,
      "loss": 0.1865,
      "step": 340
    },
    {
      "epoch": 9.597864768683275,
      "grad_norm": 0.23385104537010193,
      "learning_rate": 4.061084639512941e-05,
      "loss": 0.1886,
      "step": 345
    },
    {
      "epoch": 9.740213523131672,
      "grad_norm": 0.23520435392856598,
      "learning_rate": 4.019456426705839e-05,
      "loss": 0.2151,
      "step": 350
    },
    {
      "epoch": 9.882562277580071,
      "grad_norm": 0.2629137635231018,
      "learning_rate": 3.9771491131628506e-05,
      "loss": 0.1662,
      "step": 355
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.0421059131622314,
      "learning_rate": 3.934181607572145e-05,
      "loss": 0.1708,
      "step": 360
    },
    {
      "epoch": 10.142348754448399,
      "grad_norm": 0.2329655885696411,
      "learning_rate": 3.890573113685902e-05,
      "loss": 0.1663,
      "step": 365
    },
    {
      "epoch": 10.284697508896798,
      "grad_norm": 0.25156912207603455,
      "learning_rate": 3.846343121737449e-05,
      "loss": 0.1707,
      "step": 370
    },
    {
      "epoch": 10.427046263345195,
      "grad_norm": 0.23369675874710083,
      "learning_rate": 3.801511399730365e-05,
      "loss": 0.1758,
      "step": 375
    },
    {
      "epoch": 10.569395017793594,
      "grad_norm": 0.25867709517478943,
      "learning_rate": 3.7560979846034354e-05,
      "loss": 0.1901,
      "step": 380
    },
    {
      "epoch": 10.711743772241993,
      "grad_norm": 0.29397034645080566,
      "learning_rate": 3.710123173275405e-05,
      "loss": 0.175,
      "step": 385
    },
    {
      "epoch": 10.854092526690392,
      "grad_norm": 0.31999245285987854,
      "learning_rate": 3.663607513573546e-05,
      "loss": 0.1964,
      "step": 390
    },
    {
      "epoch": 10.99644128113879,
      "grad_norm": 0.30274343490600586,
      "learning_rate": 3.616571795050084e-05,
      "loss": 0.1668,
      "step": 395
    },
    {
      "epoch": 11.113879003558718,
      "grad_norm": 0.2537047863006592,
      "learning_rate": 3.569037039690578e-05,
      "loss": 0.1544,
      "step": 400
    },
    {
      "epoch": 11.256227758007118,
      "grad_norm": 0.25956693291664124,
      "learning_rate": 3.521024492518431e-05,
      "loss": 0.1835,
      "step": 405
    },
    {
      "epoch": 11.398576512455517,
      "grad_norm": 0.25052469968795776,
      "learning_rate": 3.4725556120997096e-05,
      "loss": 0.1609,
      "step": 410
    },
    {
      "epoch": 11.540925266903916,
      "grad_norm": 0.2565757930278778,
      "learning_rate": 3.423652060952522e-05,
      "loss": 0.18,
      "step": 415
    },
    {
      "epoch": 11.683274021352313,
      "grad_norm": 0.23026534914970398,
      "learning_rate": 3.3743356958652495e-05,
      "loss": 0.1647,
      "step": 420
    },
    {
      "epoch": 11.825622775800712,
      "grad_norm": 0.28773853182792664,
      "learning_rate": 3.324628558127942e-05,
      "loss": 0.1431,
      "step": 425
    },
    {
      "epoch": 11.96797153024911,
      "grad_norm": 0.28802698850631714,
      "learning_rate": 3.2745528636812655e-05,
      "loss": 0.1682,
      "step": 430
    },
    {
      "epoch": 12.08540925266904,
      "grad_norm": 0.2824801504611969,
      "learning_rate": 3.2241309931873756e-05,
      "loss": 0.1376,
      "step": 435
    },
    {
      "epoch": 12.227758007117437,
      "grad_norm": 0.29933905601501465,
      "learning_rate": 3.173385482027187e-05,
      "loss": 0.1577,
      "step": 440
    },
    {
      "epoch": 12.370106761565836,
      "grad_norm": 0.2741082012653351,
      "learning_rate": 3.122339010228481e-05,
      "loss": 0.1602,
      "step": 445
    },
    {
      "epoch": 12.512455516014235,
      "grad_norm": 0.28795862197875977,
      "learning_rate": 3.071014392329373e-05,
      "loss": 0.168,
      "step": 450
    },
    {
      "epoch": 12.654804270462634,
      "grad_norm": 0.24891972541809082,
      "learning_rate": 3.0194345671816616e-05,
      "loss": 0.157,
      "step": 455
    },
    {
      "epoch": 12.797153024911031,
      "grad_norm": 0.3257114589214325,
      "learning_rate": 2.9676225876986106e-05,
      "loss": 0.1603,
      "step": 460
    },
    {
      "epoch": 12.93950177935943,
      "grad_norm": 0.33003562688827515,
      "learning_rate": 2.9156016105517636e-05,
      "loss": 0.1635,
      "step": 465
    },
    {
      "epoch": 13.05693950177936,
      "grad_norm": 0.28129902482032776,
      "learning_rate": 2.8633948858213723e-05,
      "loss": 0.1681,
      "step": 470
    },
    {
      "epoch": 13.199288256227758,
      "grad_norm": 0.26873478293418884,
      "learning_rate": 2.8110257466050877e-05,
      "loss": 0.1556,
      "step": 475
    },
    {
      "epoch": 13.341637010676157,
      "grad_norm": 0.2523748576641083,
      "learning_rate": 2.7585175985895467e-05,
      "loss": 0.162,
      "step": 480
    },
    {
      "epoch": 13.483985765124554,
      "grad_norm": 0.26797357201576233,
      "learning_rate": 2.7058939095895086e-05,
      "loss": 0.1605,
      "step": 485
    },
    {
      "epoch": 13.626334519572953,
      "grad_norm": 0.2950856387615204,
      "learning_rate": 2.653178199059232e-05,
      "loss": 0.1296,
      "step": 490
    },
    {
      "epoch": 13.768683274021353,
      "grad_norm": 0.34940648078918457,
      "learning_rate": 2.600394027580767e-05,
      "loss": 0.1525,
      "step": 495
    },
    {
      "epoch": 13.911032028469752,
      "grad_norm": 0.2759568393230438,
      "learning_rate": 2.5475649863338695e-05,
      "loss": 0.1433,
      "step": 500
    },
    {
      "epoch": 14.02846975088968,
      "grad_norm": 0.2542116940021515,
      "learning_rate": 2.4947146865522412e-05,
      "loss": 0.1392,
      "step": 505
    },
    {
      "epoch": 14.170818505338078,
      "grad_norm": 0.288073867559433,
      "learning_rate": 2.441866748970796e-05,
      "loss": 0.152,
      "step": 510
    },
    {
      "epoch": 14.313167259786477,
      "grad_norm": 0.24191942811012268,
      "learning_rate": 2.3890447932686992e-05,
      "loss": 0.136,
      "step": 515
    },
    {
      "epoch": 14.455516014234876,
      "grad_norm": 0.30400770902633667,
      "learning_rate": 2.33627242751286e-05,
      "loss": 0.1404,
      "step": 520
    },
    {
      "epoch": 14.597864768683275,
      "grad_norm": 0.31088152527809143,
      "learning_rate": 2.2835732376066257e-05,
      "loss": 0.1572,
      "step": 525
    },
    {
      "epoch": 14.740213523131672,
      "grad_norm": 0.29592636227607727,
      "learning_rate": 2.2309707767483746e-05,
      "loss": 0.1459,
      "step": 530
    },
    {
      "epoch": 14.882562277580071,
      "grad_norm": 0.3488331437110901,
      "learning_rate": 2.17848855490473e-05,
      "loss": 0.1474,
      "step": 535
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.9886268973350525,
      "learning_rate": 2.1261500283030967e-05,
      "loss": 0.1299,
      "step": 540
    },
    {
      "epoch": 15.142348754448399,
      "grad_norm": 0.25719499588012695,
      "learning_rate": 2.0739785889482098e-05,
      "loss": 0.1487,
      "step": 545
    },
    {
      "epoch": 15.284697508896798,
      "grad_norm": 0.2660604417324066,
      "learning_rate": 2.0219975541673963e-05,
      "loss": 0.1307,
      "step": 550
    },
    {
      "epoch": 15.427046263345195,
      "grad_norm": 0.2510671615600586,
      "learning_rate": 1.9702301561892023e-05,
      "loss": 0.1254,
      "step": 555
    },
    {
      "epoch": 15.569395017793594,
      "grad_norm": 0.3175634741783142,
      "learning_rate": 1.9186995317600605e-05,
      "loss": 0.16,
      "step": 560
    },
    {
      "epoch": 15.711743772241993,
      "grad_norm": 0.3043859601020813,
      "learning_rate": 1.8674287118036345e-05,
      "loss": 0.1252,
      "step": 565
    },
    {
      "epoch": 15.854092526690392,
      "grad_norm": 0.28320130705833435,
      "learning_rate": 1.816440611127448e-05,
      "loss": 0.142,
      "step": 570
    },
    {
      "epoch": 15.99644128113879,
      "grad_norm": 0.2726857662200928,
      "learning_rate": 1.765758018181426e-05,
      "loss": 0.1369,
      "step": 575
    },
    {
      "epoch": 16.11387900355872,
      "grad_norm": 0.25964128971099854,
      "learning_rate": 1.7154035848728963e-05,
      "loss": 0.1183,
      "step": 580
    },
    {
      "epoch": 16.256227758007118,
      "grad_norm": 0.29001346230506897,
      "learning_rate": 1.665399816442622e-05,
      "loss": 0.16,
      "step": 585
    },
    {
      "epoch": 16.398576512455517,
      "grad_norm": 0.27484631538391113,
      "learning_rate": 1.615769061406391e-05,
      "loss": 0.1353,
      "step": 590
    },
    {
      "epoch": 16.540925266903916,
      "grad_norm": 0.3143407702445984,
      "learning_rate": 1.5665335015666386e-05,
      "loss": 0.1179,
      "step": 595
    },
    {
      "epoch": 16.683274021352315,
      "grad_norm": 0.3102850914001465,
      "learning_rate": 1.5177151420985919e-05,
      "loss": 0.1199,
      "step": 600
    },
    {
      "epoch": 16.82562277580071,
      "grad_norm": 0.34289589524269104,
      "learning_rate": 1.4693358017153492e-05,
      "loss": 0.1311,
      "step": 605
    },
    {
      "epoch": 16.96797153024911,
      "grad_norm": 0.3219952881336212,
      "learning_rate": 1.4214171029162976e-05,
      "loss": 0.1343,
      "step": 610
    },
    {
      "epoch": 17.085409252669038,
      "grad_norm": 0.2706775367259979,
      "learning_rate": 1.3739804623232278e-05,
      "loss": 0.1398,
      "step": 615
    },
    {
      "epoch": 17.227758007117437,
      "grad_norm": 0.3257673680782318,
      "learning_rate": 1.3270470811084587e-05,
      "loss": 0.1312,
      "step": 620
    },
    {
      "epoch": 17.370106761565836,
      "grad_norm": 0.2459278553724289,
      "learning_rate": 1.2806379355192588e-05,
      "loss": 0.1296,
      "step": 625
    },
    {
      "epoch": 17.512455516014235,
      "grad_norm": 0.33055445551872253,
      "learning_rate": 1.234773767502794e-05,
      "loss": 0.1421,
      "step": 630
    },
    {
      "epoch": 17.654804270462634,
      "grad_norm": 0.37403255701065063,
      "learning_rate": 1.1894750754357881e-05,
      "loss": 0.1287,
      "step": 635
    },
    {
      "epoch": 17.797153024911033,
      "grad_norm": 0.2968069016933441,
      "learning_rate": 1.1447621049630492e-05,
      "loss": 0.1225,
      "step": 640
    },
    {
      "epoch": 17.939501779359432,
      "grad_norm": 0.29609623551368713,
      "learning_rate": 1.1006548399489508e-05,
      "loss": 0.1212,
      "step": 645
    },
    {
      "epoch": 18.05693950177936,
      "grad_norm": 0.25972995162010193,
      "learning_rate": 1.0571729935459074e-05,
      "loss": 0.1257,
      "step": 650
    },
    {
      "epoch": 18.199288256227756,
      "grad_norm": 0.33610963821411133,
      "learning_rate": 1.0143359993838505e-05,
      "loss": 0.1358,
      "step": 655
    },
    {
      "epoch": 18.341637010676155,
      "grad_norm": 0.2827206254005432,
      "learning_rate": 9.721630028846199e-06,
      "loss": 0.1206,
      "step": 660
    },
    {
      "epoch": 18.483985765124554,
      "grad_norm": 0.42498868703842163,
      "learning_rate": 9.30672852705179e-06,
      "loss": 0.1359,
      "step": 665
    },
    {
      "epoch": 18.626334519572953,
      "grad_norm": 0.2971518337726593,
      "learning_rate": 8.89884092313457e-06,
      "loss": 0.1226,
      "step": 670
    },
    {
      "epoch": 18.768683274021353,
      "grad_norm": 0.2671215236186981,
      "learning_rate": 8.498149517005941e-06,
      "loss": 0.1142,
      "step": 675
    },
    {
      "epoch": 18.91103202846975,
      "grad_norm": 0.28217339515686035,
      "learning_rate": 8.104833392332936e-06,
      "loss": 0.129,
      "step": 680
    },
    {
      "epoch": 19.02846975088968,
      "grad_norm": 0.2735428214073181,
      "learning_rate": 7.719068336499118e-06,
      "loss": 0.0893,
      "step": 685
    },
    {
      "epoch": 19.17081850533808,
      "grad_norm": 0.25943416357040405,
      "learning_rate": 7.341026762038797e-06,
      "loss": 0.1228,
      "step": 690
    },
    {
      "epoch": 19.31316725978648,
      "grad_norm": 0.35446661710739136,
      "learning_rate": 6.970877629579534e-06,
      "loss": 0.1202,
      "step": 695
    },
    {
      "epoch": 19.455516014234874,
      "grad_norm": 0.3257881700992584,
      "learning_rate": 6.608786372327447e-06,
      "loss": 0.1215,
      "step": 700
    },
    {
      "epoch": 19.597864768683273,
      "grad_norm": 0.3613334894180298,
      "learning_rate": 6.254914822129082e-06,
      "loss": 0.1371,
      "step": 705
    },
    {
      "epoch": 19.740213523131672,
      "grad_norm": 0.26491299271583557,
      "learning_rate": 5.9094211371427924e-06,
      "loss": 0.112,
      "step": 710
    },
    {
      "epoch": 19.88256227758007,
      "grad_norm": 0.2988292872905731,
      "learning_rate": 5.572459731152077e-06,
      "loss": 0.1266,
      "step": 715
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.197150468826294,
      "learning_rate": 5.24418120455242e-06,
      "loss": 0.1473,
      "step": 720
    },
    {
      "epoch": 20.1423487544484,
      "grad_norm": 0.31531769037246704,
      "learning_rate": 4.924732277042429e-06,
      "loss": 0.1249,
      "step": 725
    },
    {
      "epoch": 20.284697508896798,
      "grad_norm": 0.27598118782043457,
      "learning_rate": 4.614255722049468e-06,
      "loss": 0.1237,
      "step": 730
    },
    {
      "epoch": 20.427046263345197,
      "grad_norm": 0.29353606700897217,
      "learning_rate": 4.31289030291894e-06,
      "loss": 0.0994,
      "step": 735
    },
    {
      "epoch": 20.569395017793596,
      "grad_norm": 0.33079949021339417,
      "learning_rate": 4.0207707108958885e-06,
      "loss": 0.1303,
      "step": 740
    },
    {
      "epoch": 20.71174377224199,
      "grad_norm": 0.300013929605484,
      "learning_rate": 3.738027504926539e-06,
      "loss": 0.1216,
      "step": 745
    },
    {
      "epoch": 20.85409252669039,
      "grad_norm": 0.3086075484752655,
      "learning_rate": 3.4647870533067227e-06,
      "loss": 0.126,
      "step": 750
    },
    {
      "epoch": 20.99644128113879,
      "grad_norm": 0.3544366955757141,
      "learning_rate": 3.2011714772032796e-06,
      "loss": 0.1192,
      "step": 755
    },
    {
      "epoch": 21.11387900355872,
      "grad_norm": 0.31014731526374817,
      "learning_rate": 2.9472985960735946e-06,
      "loss": 0.1479,
      "step": 760
    },
    {
      "epoch": 21.256227758007118,
      "grad_norm": 0.26426365971565247,
      "learning_rate": 2.7032818750077847e-06,
      "loss": 0.1415,
      "step": 765
    },
    {
      "epoch": 21.398576512455517,
      "grad_norm": 0.27687180042266846,
      "learning_rate": 2.4692303740170146e-06,
      "loss": 0.1115,
      "step": 770
    },
    {
      "epoch": 21.540925266903916,
      "grad_norm": 0.24101239442825317,
      "learning_rate": 2.2452486992905394e-06,
      "loss": 0.1199,
      "step": 775
    },
    {
      "epoch": 21.683274021352315,
      "grad_norm": 0.28229671716690063,
      "learning_rate": 2.031436956443422e-06,
      "loss": 0.1188,
      "step": 780
    },
    {
      "epoch": 21.82562277580071,
      "grad_norm": 0.3145182430744171,
      "learning_rate": 1.8278907057756172e-06,
      "loss": 0.1101,
      "step": 785
    },
    {
      "epoch": 21.96797153024911,
      "grad_norm": 0.29447051882743835,
      "learning_rate": 1.6347009195625845e-06,
      "loss": 0.1141,
      "step": 790
    },
    {
      "epoch": 22.085409252669038,
      "grad_norm": 0.33216801285743713,
      "learning_rate": 1.4519539413964694e-06,
      "loss": 0.0908,
      "step": 795
    },
    {
      "epoch": 22.227758007117437,
      "grad_norm": 0.27323558926582336,
      "learning_rate": 1.2797314475959748e-06,
      "loss": 0.1278,
      "step": 800
    },
    {
      "epoch": 22.370106761565836,
      "grad_norm": 0.2750703692436218,
      "learning_rate": 1.118110410702211e-06,
      "loss": 0.1079,
      "step": 805
    },
    {
      "epoch": 22.512455516014235,
      "grad_norm": 0.24710392951965332,
      "learning_rate": 9.671630650768593e-07,
      "loss": 0.1273,
      "step": 810
    },
    {
      "epoch": 22.654804270462634,
      "grad_norm": 0.30397894978523254,
      "learning_rate": 8.269568746179957e-07,
      "loss": 0.1124,
      "step": 815
    },
    {
      "epoch": 22.797153024911033,
      "grad_norm": 0.3189113438129425,
      "learning_rate": 6.975545026079861e-07,
      "loss": 0.1146,
      "step": 820
    },
    {
      "epoch": 22.939501779359432,
      "grad_norm": 0.28661516308784485,
      "learning_rate": 5.790137837069859e-07,
      "loss": 0.1306,
      "step": 825
    },
    {
      "epoch": 23.05693950177936,
      "grad_norm": 0.34197741746902466,
      "learning_rate": 4.7138769810450846e-07,
      "loss": 0.1066,
      "step": 830
    },
    {
      "epoch": 23.199288256227756,
      "grad_norm": 0.2436106950044632,
      "learning_rate": 3.7472434784062705e-07,
      "loss": 0.1333,
      "step": 835
    },
    {
      "epoch": 23.341637010676155,
      "grad_norm": 0.29899153113365173,
      "learning_rate": 2.890669353074249e-07,
      "loss": 0.1154,
      "step": 840
    },
    {
      "epoch": 23.483985765124554,
      "grad_norm": 0.2785787880420685,
      "learning_rate": 2.1445374394025442e-07,
      "loss": 0.1313,
      "step": 845
    },
    {
      "epoch": 23.626334519572953,
      "grad_norm": 0.3000323474407196,
      "learning_rate": 1.5091812110747672e-07,
      "loss": 0.1055,
      "step": 850
    },
    {
      "epoch": 23.768683274021353,
      "grad_norm": 0.23898780345916748,
      "learning_rate": 9.848846320628658e-08,
      "loss": 0.097,
      "step": 855
    },
    {
      "epoch": 23.91103202846975,
      "grad_norm": 0.2919919192790985,
      "learning_rate": 5.71882029713422e-08,
      "loss": 0.1298,
      "step": 860
    }
  ],
  "logging_steps": 5,
  "max_steps": 875,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 25,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.338483631325184e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
